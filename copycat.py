import streamlit as st
from openai import OpenAI

client = OpenAI(
    api_key=st.secrets["OPEN_AI_KEY"]
)

st.title(" IF...ì§€ì˜¥ ğŸŒ‹ ë§Œì•½ì—...ì§€ì˜¥ ğŸ’£")
st.markdown("#### Nì— ì˜í•œ! Në¥¼ ìœ„í•œ... ì§€í”¼í‹°ì™€ í•¨ê»˜í•˜ëŠ” í•‘!í! ë¦´ë ˆì´ ë§ìƒ")
st.markdown(" MBTI 'S'ë“¤ì€ ëˆˆ ê°ì•„...ê·¸ëƒ¥ ì§€ë‚˜ê°€ì£¼ì„¸ìš”")

st.success(" ì›í•˜ëŠ” ë§ìƒì— ëŒ€í•œ ì»¨ì…‰ì„ ì…ë ¥í•´ì£¼ì„¸ìš”  ")
st.success(" ë§ìƒì´ì–´ë„ íŒ©íŠ¸ì²´í¬ë¥¼ í•˜ê³  ì‹¶ì€ ë‚´ìš©ì´ ìˆë‹¤ë©´ ì§€í”¼í‹°ë°±ê³¼ íƒ­ìœ¼ë¡œ ì´ë™!  ")


tab_liar, tab_dict = st.tabs(["ë§ìƒ", "ì§€í”¼í‹°ë°±ê³¼"])

with tab_liar:

    st.markdown("ê²€ìƒ‰")
    auto_complete = st.toggle(label="ì˜ˆì‹œë¡œ ì±„ìš°ê¸°")
    example =  {
        "concept": "ì§€êµ¬ ìƒì—ì„œ ë°”ë‚˜ë‚˜ëŠ” ë¬¼ë¡  ë°”ë‚˜ë‚˜ì™€ ê´€ë ¨ëœ ëª¨ë“  ê²ƒì´ ì‚¬ë¼ì ¸ë²„ë ¸ë‹¤. ìœ ì¼í•˜ê²Œ ì¸ê³µ ë°”ë‚˜ë‚˜ ê°ë¯¸ë£Œë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ” 'ë°˜í•˜ë‚˜' ì œê³¼ íšŒì‚¬ê°€ ê³„ì† ì„±ì¥í•˜ê¸° ìœ„í•´ ì¡ì•„ì•¼ í•  ë°©í–¥ì„±ì€? ",
        "genre" : "ì•„í¬ì¹¼ë¦½ìŠ¤",
        "type" : "í¬ë§ì ",
        "feature" : "ê·€ì—¬ì›€"
    }

    def generate_prompt(concept, genre, type, feature):
        prompt = f"""
    ì†Œì„¤ê°€ì˜ ì…ì¥ì—ì„œ ë§Œì•½ì— {concept} ì— ëŒ€í•œ ì†Œì„¤ì˜ ì¤„ê±°ë¦¬ë¥¼ 100ì ì´ë‚´ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”. 
    í•´ë‹¹ ì†Œì„¤ì˜ ì¥ë¥´ëŠ” {genre}ì´ê³   {type}ì´ê³  ê·¸ë¦¬ê³  {feature}ì´ ìˆëŠ” ë¶„ìœ„ê¸°ì˜ ì†Œì„¤ì´ë¼ëŠ” ì ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”.
    ìµœëŒ€í•œ ìƒìƒë ¥ì„ ë°œíœ˜í•´ì„œ ì°½ì˜ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    ë°˜ë“œì‹œ 100ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ---
    ë§ìƒ: {concept}
    ì¥ë¥´: {genre}
    ---
        
        """.strip()
        return prompt


    def request_chat_completion(prompt):
        response = client.chat.completions.create(
            # model = "gpt-4-1106-preview",
            model = "gpt-3.5-turbo",
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  ìƒìƒë ¥ì´ í’ë¶€í•œ ì†Œì„¤ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            stream=True
        )
        return response

    def print_streaming_response(response):
        message = ""
        placeholder = st.empty()
        for chunk in response:
            delta = chunk.choices[0].delta
            if delta.content:
                message += delta.content
                placeholder.markdown(message + "â–Œ")
        placeholder.markdown(message)
        

    with st.form("form_1"):
        concept = st.text_area(
                "ì»¨ì…‰ì„ ì ì–´ì£¼ì„¸ìš”(í•„ìˆ˜)",
                value=example["concept"] if auto_complete else "",
                placeholder=example["concept"],
                height=10
                                )
        col1, col2, col3 = st.columns(3)
        with col1:
            genres = ['SF/ê³¼í•™', 'íŒíƒ€ì§€','ì²­ì¶˜ë¬¼', 'íˆì–´ë¡œë¬¼',
                    'ë¡œë§¨ìŠ¤', 'ì¶”ë¦¬/ë¯¸ìŠ¤í„°ë¦¬',
                    'ìŠ¤ë¦´ëŸ¬', 'ì•„í¬ì¹¼ë¦½ìŠ¤']
            genre = st.selectbox('ì¥ë¥´ ì„ íƒ', genres)
            value=example["genre"] if auto_complete else "",
            placeholder=example["genre"]
            
        with col2:
            types = ['í˜„ì‹¤ì ','ìê·¹ì ', 'í¬ë§ì ', 'ì ˆë§ì ']
            type = st.selectbox('íŠ¹ì§• 01 ì„ íƒ', types)
            value=example["type"] if auto_complete else "",
            placeholder=example["type"]
    
        with col3:
            features = ['êµí›ˆ', 'ë”°ëœ»í•¨','ì½”ë¯¹í•¨', 'ë°˜ì „', 'ê·€ì—¬ì›€']
            feature = st.selectbox('íŠ¹ì§• 02 ì„ íƒ', features)
            value=example["feature"] if auto_complete else "",
            placeholder=example["feature"]
        
        submit = st.form_submit_button("ì œì¶œí•˜ê¸°")
        
    if submit:
        if not concept:
            st.error("ì»¨ì…‰ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not genre:
            st.error("ì¥ë¥´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        elif not type:
            st.error("íƒ€ì…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        elif not feature:
            st.error("ë¶„ìœ„ê¸°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            prompt = generate_prompt(
                concept=concept,
                genre=genre,
                type=type,
                feature =feature,
            )
            response = request_chat_completion(prompt)
            print_streaming_response(response)
            

with tab_dict:            
        
    st.markdown("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ê²€ìƒ‰í•´ë³´ì„¸ìš”")
    

    auto_complete = st.toggle(label="ì˜ˆì‹œ ë³´ê¸°")
    example =  {
        "question": "ì „ ì„¸ê³„ ë°”ë‚˜ë‚˜ ì†Œë¹„ëŸ‰ì€?"
    }

    def generate_prompt(question):
        prompt = f"""
    {question} ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ 100ì ì´ìƒìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ---
    ì§ˆë¬¸: {question}
    ---
        
        """.strip()
        return prompt

    def request_chat_completion(prompt):
        response = client.chat.completions.create(
            # model = "gpt-4-1106-preview",
            model = "gpt-3.5-turbo",
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìµœê³ ì˜ ê²€ìƒ‰ ì‹œìŠ¤í…œì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            stream=True
        )
        return response

    def print_streaming_response(response):
        message = ""
        placeholder = st.empty()
        for chunk in response:
            delta = chunk.choices[0].delta
            if delta.content:
                message += delta.content
                placeholder.markdown(message + "â–Œ")
        placeholder.markdown(message)
        
    with st.form("form_2"):
        question = st.text_area(
                "ê¶ê¸ˆí•œ ì  íŒ©íŠ¸ ì²´í¬",
                value=example["question"] if auto_complete else "",
                placeholder=example["question"],
                height=5
                                )
        submit = st.form_submit_button("ì œì¶œí•˜ê¸°")
        
    if submit:
        if not question:
            st.error("ì§ˆë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
        else:
            prompt = generate_prompt(
                question = question
            )
            response = request_chat_completion(prompt)
            print_streaming_response(response)
            